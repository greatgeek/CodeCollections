# 面试笔记2

## HashMap 的数据结构?

HashMap 在1.7 和 1.8 做的比较大的一个改变, 1.7 之前使用使用的是数组加链表,它的数据节点是一个 Entry 节点, Entry 是它的一个内部类. 1.7 之前它的数据插入过程是使用了一个头插法, 它使用头插法会造成什么问题呢? 在并发情况下, 它的resize 过程有可能造成链表循环, 可以在下一次 Get 的时候出现一个死循环的情况. 

JDK1.8 后对它进行了一个较大的改变, 把它变成了链表+数组+红黑树的这么一个结构. 在链表长度大于8时会自动转化成红黑树. 也从原来的头插法改成了尾插法, 可以在并发情况下 resize 时解决链表循环的问题, 但是它仍然不是一个并发安全的数据结构.

扩容机制: 默认初始化容量是16, 负载因子是 0.75.  它会计算出来一个 threshold阈值, 在每次进行 put 操作前会先判断当前的 size 会不会大于这个阈值, 如果大于的时候, 它就会进行二倍扩容, 然后将原来的 Entry 进行 rehash 放入新申请的内存中. 

## 日常开发中如何HashMap的线程安全?

使用 ConcurrentHashMap. 

说一下 ConcurrentHashMap 与 Hashtable 区别.

* **底层数据结构**: JDK 1.7 的ConcurrentHashMap 底层采分段数组+链表实现,  JDK 1.8 采用 数组+链表+红黑树. Hashtable 则使用 数组+链表.
* **实现线程安全的方式**:1. 在JDK1.7 时, ConcurrentHashMap 采用分段锁, 每一把锁只锁容器中一部分数据, 多线程访问容器中不同数据段的数据时,不会存在锁竞争, 可以提高并发度. JDK 1.8 时, 摒弃了 segment 的概念, 而是直接用Node数组+链表+红黑树来实现, 并发控制使用 synchronized 和 CAS操作, 虽然JDK 1.8 中还能看到 segment 数据结构, 但已经简化了属性, 只为了兼容旧版本. 2. HashTable 采用全表锁, 使用 synchronized 来保证线程安全, 效率非常低下.
* JDK 1.7 时, segment 实现了 ReentrantLock , 所以 segment 是一种可重入锁. 每个 segment 守护一个 HashEntry 数组里的元素, 当对 HashEntry 数组的数据进行修改时,必须先获得对应的 segment 锁.
* JDK1.8 时, 取消了 segment 锁, 采用了 CAS和 synchronized 来保证并发安全. synchronized 只锁定当前链表或红黑树的首节点, 这样只要hash 不冲突, 就不会产生并发. 

## 锁升级的过程

synchronized 关键字锁的是一个对象, 可以是实例对象也可以是类对象. 锁升级的过程记录在对象头的 Mark word 中. 

锁升级的顺序是: 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁. 整个过程不可逆. 

**处于偏向锁状态时**:当一个线程访问同步代码块并获取锁时,会在对象头和栈帧中的锁记录里存储锁偏向的线程ID, 偏向锁是一个可重入锁, 当该线程再次进入同步代码块时, 只需要简单的测试一下对象头的 Mark word 里是否存储着指向当前线程的ID, 若测试成功则表示该线程获得了锁. 若出现了锁竞争, 会升级成轻量级锁.**(对象头存储该线程ID)**

**处于轻量级锁状态时**: 当一个线程进入同步代码块前,JVM会在当前线程的栈帧中创建用于存储**锁记录**的空间,然后将对象头中的 Mark word 复制到锁记录中, 然后再尝试使用CAS 将对象头中的 Mark word 替换为指向该锁记录的指针. 若替换成功, 则此线程获得锁. 若失败便线程便开始自旋. 大量的线程自旋会消耗CPU, 此时会升级成重量级锁.**(将对象头中的 mark word 复制到栈帧的锁记录空间中,再使用CAS 将对象头替换成指向该锁记录空间的指针)**

**处于重量级锁状态时:** 此时 synchronized 是非公平锁, 线程若竞争不到锁, 就会进入阻塞队列.  

## Spring 的事务隔离级别?



## Spring 的事务传播行为



## AOP 的主要实现方式?

可以使用JDK的proxy 动态代理实现,  另外一个是 cglib. 

JDK 动态代理只能为接口创建动态代理实例, 而不能对类创建动态代理.  需要使用反射技术获得被代理类的接口信息,生成一个实现了代理接口的动态代理类字节码, 再通过反射机制获得动态代理类的构造函数, 利用构造函数生成动态代理类的实例对象, 在调用具体方法前调用 invokeHandler 方法来处理. 

cglib 动态代理需要依赖asm 包, 把被代理对象类的class 文件加载进来, 修改其字节码生成子类. 

## 聊一聊反射

使用反射的话, JVM 会先去方法区里看这个类有没有加载过， 如果没有的话会有一个类加载的过程．

## nginx 常用负载均衡的算法

一致性哈希, 

加权哈希, 因为有的机器可能性能比较好, 我们可以让更多的流量落在它上面. 

轮询, 加权轮询

## tcp 三次握手



## Mysql 调优经验

索引这一块是MySQL 调优的一个比较大的方向, 创建索引的时候可能要考虑以下几个因素, 首先是覆盖索引,因为覆盖索引可以减少回表的次数. MySQL 5.6 以后对覆盖索引做了进一步的优化,  支持索引下推的功能. 把覆盖索引所覆盖的字段进一步进行筛选,尽量减少回表的次数.  这个可以使用 explain 看它执行计划时,  那个 Extra 那个字段里面有 Using index condition. 

还可以进一步对它进行优化, 如果我们存储介质使用的是机械硬盘的话, 机械硬盘的随机读写开销很大, 因为有一个磁盘寻址的开销, 我们可以把 multi range read 打开, 它可以把在回表之前, 把我们的ID 读到一个buffer 里面, 进行排序, 把原来的一个随机操作变成一个顺序操作,  这是覆盖索引可以做的一些优化.  覆盖索引可以避免排序用到的一些临时文件. 可以利用最左原则和覆盖, 所以配合, 可以减少一些索引的维护. 

对于普通索引, 若是一个写多读少的服务, 并且这个服务就是唯一性要求没有那么高, 或者业务代码可以保证唯一性时, 此时可以使用普通索引, 因为普通索引是可以用到 Change Buffer 的. Change Buffer 就可以把一些写操作给缓存下来, 在我们读的时候进行一个 merge 的操作, 这样的许就可以提高写入的速度和内存的命中率. 

还有就是要考虑索引失效了,是什么原因?

可以考虑第一个原因是不是SQL写的有问题, 比如我们对索引字段进行了一些函数操作, 或者在连接查询时, 两个表的编码不一样. 也有可能两个字段的类型不一样, 比如说 String , 赋给它一个 ID, 如果String 跟 ID 比较, 会发生隐式转换.

考虑完成自身的SQL语句之后 , 可以考虑是不是索引统计信息有问题,  若索引统计信息有问题, 可以使用 analyze table 重新统计索引信息.  因为索引信息并不是一个准确值,  它是一个随机采样的过程, 可能会出现问题, 

## explain 分析出来的索引一定是最优的么?



## 有没有遇到过索引建的不好,导致索引走得很差的情况

如果碰到这种情况时,就首先我们可以考虑, 可以用那个 force index, 但这个是不太好的, 但可以作为业务的一个应急预案. 

覆盖索引+最左原则 

## 大批量的热点数据的更新, 是如何解决的

我们可以把它写在一个内存的临时表里, 因为 innodb 会维护一个 buffer pool , 如果我们直接把大量的数据全部读进去的话, 可能会造成 flush 的一个操作, 就是把脏页刷加Mysql , 这个操作会造成我们线上业务的阻塞.