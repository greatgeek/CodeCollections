# 项目中的消息队列

## 配置文件

`application.properties` 文件

```properties
mq.nameserver.addr=xxx.xxx.xxx.xxx:9876
mq.topicname=stock
```

## 两个 Bean: MqProducer 和 MqConsumer

使用消息队列需要引入两个 `Bean`。

```java
@Component
public class MqProducer{
    private DefaultMQProducer producer;
    
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    
    @Value("${mq.topic.name}")
    private String topicName;
    
    @PostConstruct
    public void init(){
        // mq producer 的初始化
        producer = new DefaultMQProducer("producer");
        producer.setNameSrvAddr(nameAddr);
        producer.start();
    }
}
```

```java
@Component
public class MqProducer{
    private DefaultMQPushConsumer consumer;
    
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    
    @Value("${mq.topic.name}")
    private String topicName;
    
    @Autowired
    private ItemStockDOMapper itemDOMapper;
    
    @PostConstruct
    public void init(){
        // mq producer 的初始化
        consumer = new DefaultMQPushConsumer("consumer");
        consumer.setNameSrvAddr(nameAddr);
        consumer.subscribe(topicName,"*"); // 订阅 topic
        
        consumer.registerMessageListener(new MessageListenerConcurrently(){
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyStatus){
                // 实现库存真正到数据库内扣减的逻辑
                Message msg = msgs.get(0);
                String jsonString = new String(msg.getBody());
                Map<String,Object> map = JSON.parseObject(jsonString,Map.class);
                Integer itemId = (Integer)map.get("itemId");
                Integer amount = (Integer)map.get("amount");
                
                itemStockDOMapper.decreaseStock(itemId,amount);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        consumer.start();
    }
}
```

```java
// 同步库存扣减消息
public SendResult asyncReduceStock(Integer itemId,Integer amount){
    Map<String,Object> bodyMap = new HashMap<>();
    bodyMap.put("itemId",itemId);
    bodyMap.put("amount",amount);
    Message message = new Message(topicName,"increase",
                                 JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
    return producer.send(message);
}
```

## 问题：

1. 异步消息发送失败；
2. 扣减操作执行失败；
3. 下单失败无法正确回补库存；

## 事务型消息

关于分布式事务：二阶段提交协议、三阶段提交协议。



## 顺序消息

### 全局顺序消息

RocketMQ 在默认情况下不保证顺序，比如创建一个 Topic，默认八个写队列，八个读队列。这时候一条消息可能被写入任意一个队列里；在数据的读取过程中，可能有多个 Consumer，每个 Consumer 也可能启动多个线程并行处理，所以消息被哪个 Consumer 消费，被消费的顺序和写入的顺序是否一致是不确定的。

**要保证全局顺序消息，需要先把 Topic 的读写队列数设置为一，然后 Producer 和 Consumer 的并发设置也要是一。简单来说，为了保证整个 Topic 的全局消息有序，只能消除所有的并发处理，各部分都设置成单线程处理**。这时高并发、高吞吐量的功能完全用不上了。

### 部分顺序消息

**要保证部分消息有序，需要发送端和消费端配合处理。**在发送端，要做到把同一业务 ID 的消息发送到同一个 Message Queue；在消费过程中，要做到从同一个 Message Queue 读取的消息不被并发处理，这样才能达到部分有序。 

## 消息重复问题

消息重复问题一般情况不会发生，但是如果消息量大，网络有波动，消息重复是个大概率事件。比如 Producer 有个函数 setRetryTimesWhenSendFailed，设置在同步方式下自动重试的次数，默认值是2，这样当第一次发送消息时，Broker 端接收到消息但是没有正确返回发送成功的状态，就造成了消息的重复。

解决消息重复有两种方法：第一种方法是保证消费逻辑的幂等性（多次调用和一次调用效果相同）；另一种方法是维护一个已消费消息的记录，消费前查询这个消息是否被消费过。这两种方法都需要使用者自己实现。

这个问题需要结合实际的场景来思考：

* 写数据库场景。消息消费前先根据主键查一下，如果数据已经存在了，就不用插入了。
* 写 Redis 场景。Redis 的 Set 操作是天然幂等性的，可以不作任何操作。
* 若是其他场景。那就需要让生产者发送每条数据时，里面加一个全局唯一的 id。然后消费者要消费时，先根据这个 id 去 Redis 里查一下，看之前消费过么，如果没有消费过就处理。处理后就将这个 id 写入 Redis。如果消费过了，就丢弃。

